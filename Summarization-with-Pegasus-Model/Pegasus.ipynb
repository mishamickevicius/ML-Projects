{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911dc1d-8abe-457a-b9dd-8c4a6bc85cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d86cd98-6758-4cdf-a540-11b19ea4b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79655d74-7bf7-4aa4-a66e-50ba8aaeea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d25b33-9802-49e4-8ba5-70ea63e2aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A recurrent neural network (RNN) is one of the two broad types of artificial neural network, characterized by direction of the flow of information between its layers. In contrast to the uni-directional feedforward neural network, it is a bi-directional artificial neural network, meaning that it allows the output from some nodes to affect subsequent input to the same nodes. Their ability to use internal state (memory) to process arbitrary sequences of inputs[1][2][3] makes them applicable to tasks such as unsegmented, connected handwriting recognition[4] or speech recognition.[5][6] The term \"recurrent neural network\" is used to refer to the class of networks with an infinite impulse response, whereas \"convolutional neural network\" refers to the class of finite impulse response. Both classes of networks exhibit temporal dynamic behavior.[7] A finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that cannot be unrolled.\n",
    "\n",
    "Additional stored states and the storage under direct control by the network can be added to both infinite-impulse and finite-impulse networks. Another network or graph can also replace the storage if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated states or gated memory and are part of long short-term memory networks (LSTMs) and gated recurrent units. This is also called Feedback Neural Network (FNN). Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.[8]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25edfa04-bd7c-41e5-822e-ba1e5ea54e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2e067e-2d56-458b-bdd7-c821be729dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e78cea4-bc12-4020-87ba-ba3f8de829ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   202, 27441, 14849,   952,   117,   114,  6989,   121, 37390,\n",
       "          4958, 14849,   952,   108,  2050,   120,   126,   871,   109,  2940,\n",
       "           135,   181, 11406,   112,  2384,  5751,  3196,   112,   109,   310,\n",
       "         11406,   107,     1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03559341-9e63-4c09-86b9-ec81ed4c3a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>A recurrent neural network is a bi-directional artificial neural network, meaning that it allows the output from some nodes to affect subsequent input to the same nodes.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(summary[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de91f5c-ad55-4523-a1b3-801053edaf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073c43fb-4966-41bf-b17e-bab4f58417a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5977414-5109-4b4c-8c34-3f3ddaad8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello and this is some text. And\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c080004e-7709-4af4-ada2-081c352a733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = tokenizer(text,  truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a37f11-d05a-43f8-85df-e57ee1a3c8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3622569a-9209-4465-8f4c-2769783c9108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8087,  111,  136,  117,  181, 1352,  107,  325,    1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokens['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c2fcaee-e920-4127-89d0-9b4d6c2a9bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.max_len_single_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c314d2bc-f5dd-4304-bcb8-a4f7b8855c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_words_and_punctuation(text):\n",
    "    # Define the regex pattern for words (considering words as sequences of alphanumeric characters)\n",
    "    word_pattern = r'\\b\\w+\\b'\n",
    "    # Define the regex pattern for punctuation marks (common punctuation marks)\n",
    "    punctuation_pattern = r'[.,!?;:()\\'\"-]'\n",
    "\n",
    "    # Find all words using the word pattern\n",
    "    words = re.findall(word_pattern, text)\n",
    "    # Find all punctuation marks using the punctuation pattern\n",
    "    punctuation_marks = re.findall(punctuation_pattern, text)\n",
    "\n",
    "    # Count the number of words and punctuation marks\n",
    "    word_count = len(words)\n",
    "    punctuation_count = len(punctuation_marks)\n",
    "\n",
    "    return word_count, punctuation_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bd7c4e4-02b0-41e6-a6cf-608fa9588061",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"This sentence is. six words only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "203e229e-28bd-44fc-9c14-cd61d9413676",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count, punct_count = count_words_and_punctuation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "328d42a8-1e3d-4f75-aef6-c7848e1a130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e94ee299-e1a6-4d23-b312-3c6b65a27af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count / max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0fff898-e491-4b99-be13-4a7dd48c5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_equal_words(text):\n",
    "    word_pattern = r'\\b\\w+\\b'\n",
    "    \n",
    "    elements = re.findall(word_pattern, text)\n",
    "    \n",
    "    total_elements = len(elements)\n",
    "    half_elements = total_elements // 2\n",
    "    \n",
    "    running_count = 0\n",
    "    split_index = 0\n",
    "    \n",
    "    for match in re.finditer(word_pattern, text):\n",
    "        running_count += 1\n",
    "        if running_count >= half_elements:\n",
    "            split_index = match.end()\n",
    "            break\n",
    "    \n",
    "    part1 = text[:split_index]\n",
    "    part2 = text[split_index:]\n",
    "    \n",
    "    return part1, part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af44c6-2a07-40a7-8203-c33bc62e4792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
