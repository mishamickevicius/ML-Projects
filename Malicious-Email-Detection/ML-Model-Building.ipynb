{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd4dc93-f05c-412a-9593-29d0c4b04036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01270faa-07f0-45b2-b61f-d2e7c2d16c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = os.path.join('/home/dude/Desktop/data/email_data', 'full_dataset.csv')  LINUX\n",
    "filepath = os.path.join('/Users/misham/Desktop/data/email_data', 'full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee106b9-5795-429d-abe3-512c815ce91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9259ebdf-fed7-488e-8214-0aedad7d8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba05841-0518-4c84-8ec8-57e98cc4ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27082 entries, 0 to 27081\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   subject  27082 non-null  object \n",
      " 1   body     27082 non-null  object \n",
      " 2   label    27082 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 634.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8edf425c-5649-497b-9d8e-6fa9c17e75de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d837ecbd-a39a-4053-9226-c1693536e97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    19165\n",
       "1     7917\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b5fde3-8334-4ea8-968e-3507b7223ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "ham_amt = int(df['label'].value_counts().iloc[0])\n",
    "spam_amt = int(df['label'].value_counts().iloc[1])\n",
    "\n",
    "percentage_of_spam = round(spam_amt / total, 2)\n",
    "percentage_of_ham = round(ham_amt / total, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b26b384-06d8-49dc-86e5-7b2707629bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b407e7-d782-4f32-8f53-d81a5a8c50c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b5b1a9-2a2c-4d2f-8780-beaf52265ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d746798e-045d-4691-9555-f51b2821b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aacfc124-b2d4-4cd8-b291-e388cb0e05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b98199-a5c9-4baf-9248-b91420b3d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject'] = df['subject'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2a5e82e-0ebb-4834-8d8a-7d76d6326be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query : letter frequencies text identification</td>\n",
       "      <td>posting inquiry sergei atamas ( satamas @ umab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk</td>\n",
       "      <td>colleague researching differing degrees risk p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier morning phone friend mine living south...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call abstracts : optimality syntactic theory</td>\n",
       "      <td>content - length : 4437 call papers best good ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          subject  \\\n",
       "0         job posting - apple-iss research center   \n",
       "1  query : letter frequencies text identification   \n",
       "2                                            risk   \n",
       "3                        request book information   \n",
       "4    call abstracts : optimality syntactic theory   \n",
       "\n",
       "                                                body  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  posting inquiry sergei atamas ( satamas @ umab...      0  \n",
       "2  colleague researching differing degrees risk p...      0  \n",
       "3  earlier morning phone friend mine living south...      0  \n",
       "4  content - length : 4437 call papers best good ...      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9519652-32de-4d23-9f7a-237965f4a342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ce36f-b5aa-4091-b0d7-decb676302f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0f329c-3efa-47c8-93e3-35bd7be41100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e9a7c08-500f-4036-942a-809e918fcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Subject and Body\n",
    "df['text'] = df['subject'] + \" \" + df['body']\n",
    "\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a69fe39-13c5-4296-8aba-9c484bc8f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5adc3ef2-d0c7-4268-92d5-c501ebeaee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b01f43b-1765-4721-bb2f-d8cf56a06641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d8386d1-2c82-470d-9adb-de3fe8318c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3307bc3e-441e-4644-8aa6-bebbd2213e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, accuracy_score, PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cef5f490-5ab6-4096-a4f1-07eb8a3fffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics(true, pred, **kwargs):\n",
    "    name = kwargs.get('name', None)\n",
    "    print(f\"Metrics for {name}\")\n",
    "    print(f\"Recall ---> {round(recall_score(true, pred), 2)}\")\n",
    "    print(f\"Precision ---> {round(precision_score(true, pred), 2)}\")\n",
    "    print(f\"Accuracy ---> {round(accuracy_score(true, pred), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53889e7b-43f0-4b12-a94d-c19aa63bcc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3848\n",
      "           1       0.98      0.92      0.95      1569\n",
      "\n",
      "    accuracy                           0.97      5417\n",
      "   macro avg       0.97      0.96      0.97      5417\n",
      "weighted avg       0.97      0.97      0.97      5417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eda27c46-b1ae-4b56-9ebe-db233533e824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3816,   32],\n",
       "       [ 118, 1451]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc218af0-ad4f-42c4-9f11-147f3db04ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAGdCAYAAABDxkoSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3NElEQVR4nO3deVxV9b7/8TcgbAXdKCpTDpmWimNq4a60TAING620TLE0jx60K56UKHOqczDtHofUbDLsqKVWNmgOhKGnxDSKHDLLobR0gxOipICyf3/4c9dekotlmwvV63ke63HYa33Xd3/kXG+fPp/vdy0fl8vlEgAAgAW+lR0AAAD44yGBAAAAlpFAAAAAy0ggAACAZSQQAADAMhIIAABgGQkEAACwjAQCAABYRgIBAAAsq1bZAZxXcnhPZYcAVDk1IrtUdghAlXSm+KcKnd+b/0zyr3eF1+aqSqpMAgEAQJVRerayI6jyaGEAAADLqEAAAGDkKq3sCKo8EggAAIxKSSDMkEAAAGDgogJhijUQAADAMioQAAAY0cIwRQIBAIARLQxTtDAAAIBlVCAAADDiQVKmSCAAADCihWGKFgYAALCMCgQAAEbswjBFAgEAgAEPkjJHCwMAAFhGBQIAACNaGKZIIAAAMKKFYYoEAgAAI54DYYo1EAAAwDIqEAAAGNHCMEUCAQCAEYsoTdHCAAAAllGBAADAiBaGKRIIAACMaGGYooUBAAAsI4EAAMDA5TrrtcOKF154QW3btpXdbpfdbpfD4dDKlSvd12+66Sb5+Ph4HEOHDvWYY9++fYqPj1dgYKBCQ0M1evRonTlzxmNMZmamOnToIJvNpmbNmiktLc3y74gWBgAARpW0BqJBgwaaPHmyrrzySrlcLs2fP1933HGHvvzyS7Vq1UqS9Mgjj2jSpEnuewIDA90/nz17VvHx8QoPD9eGDRt08OBBDRgwQP7+/vrXv/4lSdq7d6/i4+M1dOhQLVy4UBkZGRo8eLAiIiIUFxdX7lh9XC6Xy0t/7t+l5PCeyg4BqHJqRHap7BCAKulM8U8VOv/pnOVem6t6+16/6/6QkBBNnTpVgwYN0k033aT27dtr+vTpZY5duXKlevXqpQMHDigsLEySNHfuXCUnJ+vQoUMKCAhQcnKyVqxYoW3btrnv69u3r/Lz87Vq1apyx0ULAwAAo9JS7x2X6OzZs3rzzTdVWFgoh8PhPr9w4ULVq1dPrVu3VkpKin7++Wf3taysLLVp08adPEhSXFycCgoKtH37dveYmJgYj++Ki4tTVlaWpfhoYQAAYOTFFkZRUZGKioo8ztlsNtlstjLHb926VQ6HQ6dPn1bNmjW1bNkyRUVFSZIeeOABNW7cWJGRkdqyZYuSk5O1c+dOvfPOO5Ikp9PpkTxIcn92Op0XHVNQUKBTp06pRo0a5fpzkUAAAGDkxZdppaamauLEiR7nxo8frwkTJpQ5vnnz5srJydHx48f11ltvKSEhQevWrVNUVJSGDBniHtemTRtFRESoe/fu2r17t5o2beq1mMuDBAIAgAqUkpKiUaNGeZz7reqDJAUEBKhZs2aSpI4dO2rz5s2aMWOGXnzxxQvGRkdHS5J27dqlpk2bKjw8XJs2bfIYk5ubK0kKDw93//f5c78eY7fby119kFgDAQDAhVylXjtsNpt7W+b542IJhFFpaekFLZDzcnJyJEkRERGSJIfDoa1btyovL889Jj09XXa73d0GcTgcysjI8JgnPT3dY51FeVCBAADAqJKeRJmSkqKePXuqUaNGOnHihBYtWqTMzEytXr1au3fv1qJFi3Trrbeqbt262rJli5KSktS1a1e1bdtWkhQbG6uoqCj1799fU6ZMkdPp1NixY5WYmOhOWoYOHapZs2ZpzJgxevjhh7V27VotWbJEK1assBQrCQQAAFVEXl6eBgwYoIMHDyo4OFht27bV6tWrdcstt2j//v366KOPNH36dBUWFqphw4bq3bu3xo4d677fz89Py5cv17Bhw+RwOBQUFKSEhASP50Y0adJEK1asUFJSkmbMmKEGDRrolVdesfQMCInnQABVGs+BAMpW4c+ByHrDa3NVd9zvtbmqEioQAAAY8TItUyyiBAAAllGBAADAiAqEKRIIAAAMrL5F86+IFgYAALCMCgQAAEa0MEyRQAAAYOTFl2n9WZFAAABgRAXCFGsgAACAZVQgAAAwooVhigQCAAAjWhimaGEAAADLqEAAAGBEC8MUCQQAAEa0MEzRwgAAAJZRgQAAwIgKhCkSCAAAjFgDYYoWBgAAsIwKBAAARrQwTJFAAABgRAvDFAkEAABGVCBMsQYCAABYRgUCAAAjWhimSCAAADCihWGKFgYAALCMCgQAAEZUIEyRQAAAYORyVXYEVR4tDAAAYBkVCAAAjGhhmCKBAADAiATCFC0MAABgGRUIAACMeJCUKRIIAACMaGGYIoEAAMCIbZymWAMBAAAsowIBAIARLQxTJBAAABiRQJiihQEAACwjgQAAwMhV6r3DghdeeEFt27aV3W6X3W6Xw+HQypUr3ddPnz6txMRE1a1bVzVr1lTv3r2Vm5vrMce+ffsUHx+vwMBAhYaGavTo0Tpz5ozHmMzMTHXo0EE2m03NmjVTWlqa5V8RCQQAAAauUpfXDisaNGigyZMnKzs7W59//rluvvlm3XHHHdq+fbskKSkpSR988IGWLl2qdevW6cCBA7r77rvd9589e1bx8fEqLi7Whg0bNH/+fKWlpWncuHHuMXv37lV8fLy6deumnJwcjRw5UoMHD9bq1astxerjclWNvSolh/dUdghAlVMjsktlhwBUSWeKf6rQ+X9+KclrcwUOmfa77g8JCdHUqVN1zz33qH79+lq0aJHuueceSdI333yjli1bKisrS507d9bKlSvVq1cvHThwQGFhYZKkuXPnKjk5WYcOHVJAQICSk5O1YsUKbdu2zf0dffv2VX5+vlatWlXuuKhAAABgVFrqtaOoqEgFBQUeR1FRkWkIZ8+e1ZtvvqnCwkI5HA5lZ2erpKREMTEx7jEtWrRQo0aNlJWVJUnKyspSmzZt3MmDJMXFxamgoMBdxcjKyvKY4/yY83OUFwkEAABGXlwDkZqaquDgYI8jNTX1N79669atqlmzpmw2m4YOHaply5YpKipKTqdTAQEBql27tsf4sLAwOZ1OSZLT6fRIHs5fP3/tYmMKCgp06tSpcv+K2MYJAEAFSklJ0ahRozzO2Wy23xzfvHlz5eTk6Pjx43rrrbeUkJCgdevWVXSYlpFAAABgZHHx48XYbLaLJgxGAQEBatasmSSpY8eO2rx5s2bMmKE+ffqouLhY+fn5HlWI3NxchYeHS5LCw8O1adMmj/nO79L49Rjjzo3c3FzZ7XbVqFGj3HHSwgAAwMiLayB+fyjn1lF07NhR/v7+ysjIcF/buXOn9u3bJ4fDIUlyOBzaunWr8vLy3GPS09Nlt9sVFRXlHvPrOc6POT9HeVGBAADAqJKeRJmSkqKePXuqUaNGOnHihBYtWqTMzEytXr1awcHBGjRokEaNGqWQkBDZ7XaNGDFCDodDnTt3liTFxsYqKipK/fv315QpU+R0OjV27FglJia6qyBDhw7VrFmzNGbMGD388MNau3atlixZohUrVliKlQQCAIAqIi8vTwMGDNDBgwcVHBystm3bavXq1brlllskSdOmTZOvr6969+6toqIixcXFac6cOe77/fz8tHz5cg0bNkwOh0NBQUFKSEjQpEmT3GOaNGmiFStWKCkpSTNmzFCDBg30yiuvKC4uzlKsPAcCqMJ4DgRQtgp/DsT0v3ltrsCRL3ptrqqECkQV9+ay5Vq8bIUOHDy34KVZk8Ya+tAD6uK45jfv+c/iZVq8bIUO5h5S7dp2xd50g0YOfUg2W0CFxbl67X816+XX9ZMzV40bXKakYQ+p63XXuq/PfnWBVn20Ts68Q/L391dU82Z6dEiC2rZqUWExAVb9bcgA/e1v/XV544aSpK+//lbP/HOaVq3+WHXq1Nb4cf/QLbfcqEYNI3Xo0FG99/4qjZ8wVQUFJyo5cngdL9MyxSLKKi68fj0lDX1IS+Y9r8WvztS1HdtpxOOTtGvPD2WOX7HmY02b+5qGPdxP7y96SZMeH6lVGes148W0S45h0xdbFNs74Tevf7n1a42ZMFl39YrT0tdm6eYuDj2a8rS+2/O9e8zlDS/TE6P+rndef0Gvz3lOkeFhGpL0pI4ey7/kuABv++mng3ryyVRd27mnoh236uPMT/XO2/MUFXWVIiPDFBkZpuTkp9Xu6u4aNDhJcXHd9PJL/1vZYQOVggpEFXfTDZ09Pv/P3wZq8bIV+mr7N2p2ReMLxuds3aGr20QpPrabJOmyiDDdestN2vL1N+4xpaWlenXBUr31/kodPnJMjRtdpqED71dst0srly9Y8p6uj+6kh/ude7TqiCEDlLX5Cy166wONHzNCktzxnDfm0Uf0zvLV+nb3XnXudPUlfS/gbctXpHt8fmrcs/rbkP6KvraDXkt7U/f1GeK+tmfPD3pq3LN6PW2m/Pz8dPbs2f/rcFGRvLiN88+KCsQfyNmzZ/XhR5k6dfq02rcuu/Tfvk1Lfb1zl7Z+vVOStP+ng1qftVldOv/S8nj5P4v1/qoMjRs9Qu8umKsB992lxydN1eYvt1xSXF9t3yFHp/Ye566L7qivtu8oc3xJSYmWvrdStWoGqXmzKy7pO4GK5uvrq/vuu11BQYHa+Fl2mWOC7bVUUHCS5OHPqJLexvlHYrkCcfjwYc2bN09ZWVnux2KGh4fruuuu08CBA1W/fn2vB/lX9+3uver3t1EqLi5WYI0amvGvp9S0yYXVB+ncv+kfO16g/sMek1wunTl7VvfdeauGJPSVJBUXF+uV1xfr5Rmpat+6pSSp4WUR+mLLdi19b6Wuubqt5fgOHzmmuiF1PM7VC6mjw0eOeZzL/PQzjR4/WadPF6l+3RC9NP2fqlM72PL3ARWpdesW+mT9+6pe3aaTJwt1z72DtWPHdxeMq1u3jp58YqReeXVhJUQJVD5LCcTmzZsVFxenwMBAxcTE6KqrrpJ07glWM2fO1OTJk7V69Wp16tTpovMUFRVd8CIR36IiS0/q+itp0qiB3k6brRMnC7Xm40/05D//V2mzppSZRGz6Yotefn2xxv4jUW1bNde+Hw9o8owXNfe1RRr60APa9+NBnTpdpEdGPuFxX0nJGbW8qqn78zUxd7l/Lj1bquKSEo9zvWJvdrcnyuvaDu30dtpsHcs/rrc+WKXHnkrVopenq26d2pbmASrSzp271fGaWAXba6l373jNe3W6bo7p7ZFE1KpVUx+897p27PhWEyexBuJPiRaGKUsJxIgRI3Tvvfdq7ty58vHx8bjmcrk0dOhQjRgxwvSNXqmpqZo4caLHubGjH9W4Mf9jJZy/DH9/fzVqEClJatXiSm3/5lstWPqexo959IKxs15+XbfF3ax7bu8hSbqqaROdOl2kic/O1JCEvvr5/78oZc7UiQqrX++C7znv7bTZ7p+3bP9G016Yp9dmTXGfCwoKdP9cr24dHTnqWW04fPSY6tX1rEoE1qiuRg0i1ahBpNq1bqlb+wzSOx+s1iMD+lj6fQAVqaSkRLt3fy9J+uLLrerUsb1GDB+svycmS5Jq1gzSh8sX6sSJQvW+d7DOnDlTidGiorjYhWHKUgLx1VdfKS0t7YLkQZJ8fHyUlJSkq682XxBX1otFfE9U7J7eP5PSUpeKi0vKvHa6qEi+vp7/+/j5nlvq4nK51PTyRgoI8NfB3EMXbVecT1gkyZl3WH5+fh7nfq1dq5bamJ2j/n1+qVBkbf5S7Vq1NPlznKtsAFWZr6+vewt0rVo1tXLFIhUVFenOuweW65XMwJ+VpQTi/Es6WrQoewHfpk2bLnhFaFnKerFISfFhK6H8ZUx74TV1cXRSRFioCn/+WSvWZGrzl1v04r+fkSSlPP2cQuvVVdKwhyRJN14frdfffEctrmqqtlEttO/HA3r+5dd14/XR8vPzU1BQoAbe31tTZr4kV2mprm7bSicLf9aXW7arZlCg7rj1FssxPnjfHXoocYzS3nhbXa+7Vis/Wqft33ynCcnnKiQ/nzqtl+a/qW43RKt+vRAdyy/QG+98oLzDRxR3iTs/gIrwz2ce16pVH2vf/p9Uq1ZN3d/3Tt14o0O3xj+gWrVqatWHb6hGYHUNGDhCdnst2e21JEmHDh1RKf/G+udCC8OUpQTiscce05AhQ5Sdna3u3bu7k4Xc3FxlZGTo5Zdf1nPPPVchgf5VHc3P1xNPP6dDR46qVlCQrmrWRC/++xldd20HSdLB3Dz5/qoi9LeE++Xj46PnX3pdeYeOqE6dYN10fbQeHfLLcxxGPDJAdWoH65X/LNH+A07ZawapZfNml9xKuLpNlJ6dkKznX5qvGS+mqXGDyzQz9SldecXlks5VQPb+sF/vr/xIx44fV227Xa1bXqX5c6aWuRUVqCz169fTa/NmKCIiVMePn9DWrTt0a/wD+ijjv7qxq0PR0ef+3n37zQaP+5peGa0ffvixMkJGRfkT757wFsuPsl68eLGmTZum7Oxs99YlPz8/dezYUaNGjdJ99913SYHwKGvgQjzKGihbRT/KunBSP6/NFTTuz7lTx/I2zj59+qhPnz4qKSnR4cPn2g716tXzWIAHAAD+3C75SZT+/v6KiIjwZiwAAFQNrGkxxaOsAQAwYhGlKR5lDQAALKMCAQCAEbswTJFAAABgRAvDFC0MAABgGRUIAAAMeBeGORIIAACMaGGYooUBAAAsowIBAIARFQhTJBAAABixjdMUCQQAAEZUIEyxBgIAAFhGBQIAAAMXFQhTJBAAABiRQJiihQEAACyjAgEAgBFPojRFAgEAgBEtDFO0MAAAgGVUIAAAMKICYYoEAgAAA5eLBMIMLQwAAGAZFQgAAIxoYZgigQAAwIgEwhQJBAAABjzK2hxrIAAAgGUkEAAAGJW6vHdYkJqaqmuuuUa1atVSaGio7rzzTu3cudNjzE033SQfHx+PY+jQoR5j9u3bp/j4eAUGBio0NFSjR4/WmTNnPMZkZmaqQ4cOstlsatasmdLS0izFSgIBAIBRqRcPC9atW6fExERt3LhR6enpKikpUWxsrAoLCz3GPfLIIzp48KD7mDJlivva2bNnFR8fr+LiYm3YsEHz589XWlqaxo0b5x6zd+9excfHq1u3bsrJydHIkSM1ePBgrV69utyx+riqyGbXksN7KjsEoMqpEdmlskMAqqQzxT9V6PzH+3f32lzB/8m45HsPHTqk0NBQrVu3Tl27dpV0rgLRvn17TZ8+vcx7Vq5cqV69eunAgQMKCwuTJM2dO1fJyck6dOiQAgIClJycrBUrVmjbtm3u+/r27av8/HytWrWqXLFRgQAAwMBV6vLaUVRUpIKCAo+jqKioXHEcP35ckhQSEuJxfuHChapXr55at26tlJQU/fzzz+5rWVlZatOmjTt5kKS4uDgVFBRo+/bt7jExMTEec8bFxSkrK6vcvyMSCAAAjLy4BiI1NVXBwcEeR2pqqnkIpaUaOXKkrr/+erVu3dp9/oEHHtCCBQv08ccfKyUlRf/5z3/04IMPuq87nU6P5EGS+7PT6bzomIKCAp06dapcvyK2cQIAUIFSUlI0atQoj3M2m830vsTERG3btk2ffPKJx/khQ4a4f27Tpo0iIiLUvXt37d69W02bNvVO0OVAAgEAgJHFxY8XY7PZypUw/Nrw4cO1fPlyrV+/Xg0aNLjo2OjoaEnSrl271LRpU4WHh2vTpk0eY3JzcyVJ4eHh7v8+f+7XY+x2u2rUqFGuGGlhAABg4M01EJa+1+XS8OHDtWzZMq1du1ZNmjQxvScnJ0eSFBERIUlyOBzaunWr8vLy3GPS09Nlt9sVFRXlHpOR4bm4Mz09XQ6Ho9yxkkAAAFBFJCYmasGCBVq0aJFq1aolp9Mpp9PpXpewe/duPf3008rOztb333+v999/XwMGDFDXrl3Vtm1bSVJsbKyioqLUv39/ffXVV1q9erXGjh2rxMREdyVk6NCh2rNnj8aMGaNvvvlGc+bM0ZIlS5SUlFTuWNnGCVRhbOMEylbR2ziP9b7Ja3PVeTuz3GN9fHzKPP/aa69p4MCB2r9/vx588EFt27ZNhYWFatiwoe666y6NHTtWdrvdPf6HH37QsGHDlJmZqaCgICUkJGjy5MmqVu2XlQuZmZlKSkrS119/rQYNGuipp57SwIEDyx8rCQRQdZFAAGWr6ATi6F03em2ukGXrvDZXVcIiSgAAjLy4iPLPijUQAADAMioQAAAYuKhAmCKBAADAiATCFC0MAABgGRUIAAAMaGGYI4EAAMCIBMIULQwAAGAZFQgAAAxoYZgjgQAAwIAEwhwJBAAABiQQ5lgDAQAALKMCAQCAkavst2LiFyQQAAAY0MIwRwsDAABYRgUCAAADVyktDDMkEAAAGNDCMEcLAwAAWEYFAgAAAxe7MEyRQAAAYEALwxwtDAAAYBkVCAAADNiFYY4EAgAAA5ersiOo+kggAAAwoAJhjjUQAADAMioQAAAYUIEwRwIBAIABayDM0cIAAACWUYEAAMCAFoY5EggAAAx4lLU5WhgAAMAyKhAAABjwLgxzJBAAABiU0sIwRQsDAABYRgUCAAADFlGaI4EAAMCAbZzmSCAAADDgSZTmWAMBAAAsI4EAAMDAVerjtcOK1NRUXXPNNapVq5ZCQ0N15513aufOnR5jTp8+rcTERNWtW1c1a9ZU7969lZub6zFm3759io+PV2BgoEJDQzV69GidOXPGY0xmZqY6dOggm82mZs2aKS0tzVKsJBAAABiUuny8dlixbt06JSYmauPGjUpPT1dJSYliY2NVWFjoHpOUlKQPPvhAS5cu1bp163TgwAHdfffd7utnz55VfHy8iouLtWHDBs2fP19paWkaN26ce8zevXsVHx+vbt26KScnRyNHjtTgwYO1evXqcsfq43JVjU5PyeE9lR0CUOXUiOxS2SEAVdKZ4p8qdP5tV/Ty2lyt9yy/5HsPHTqk0NBQrVu3Tl27dtXx48dVv359LVq0SPfcc48k6ZtvvlHLli2VlZWlzp07a+XKlerVq5cOHDigsLAwSdLcuXOVnJysQ4cOKSAgQMnJyVqxYoW2bdvm/q6+ffsqPz9fq1atKldsVCAAADBwuXy8dhQVFamgoMDjKCoqKlccx48flySFhIRIkrKzs1VSUqKYmBj3mBYtWqhRo0bKysqSJGVlZalNmzbu5EGS4uLiVFBQoO3bt7vH/HqO82POz1EeJBAAABi4XN47UlNTFRwc7HGkpqaaxlBaWqqRI0fq+uuvV+vWrSVJTqdTAQEBql27tsfYsLAwOZ1O95hfJw/nr5+/drExBQUFOnXqVLl+R2zjBACgAqWkpGjUqFEe52w2m+l9iYmJ2rZtmz755JOKCu13IYEAAMDAm+/CsNls5UoYfm348OFavny51q9frwYNGrjPh4eHq7i4WPn5+R5ViNzcXIWHh7vHbNq0yWO+87s0fj3GuHMjNzdXdrtdNWrUKFeMtDAAADDw5hoIa9/r0vDhw7Vs2TKtXbtWTZo08bjesWNH+fv7KyMjw31u586d2rdvnxwOhyTJ4XBo69atysvLc49JT0+X3W5XVFSUe8yv5zg/5vwc5UEFAgCAKiIxMVGLFi3Se++9p1q1arnXLAQHB6tGjRoKDg7WoEGDNGrUKIWEhMhut2vEiBFyOBzq3LmzJCk2NlZRUVHq37+/pkyZIqfTqbFjxyoxMdFdCRk6dKhmzZqlMWPG6OGHH9batWu1ZMkSrVixotyxso0TqMLYxgmUraK3cX7R8A6vzdVh/3vlHuvjU3bF4rXXXtPAgQMlnXuQ1D/+8Q+98cYbKioqUlxcnObMmeNuT0jSDz/8oGHDhikzM1NBQUFKSEjQ5MmTVa3aL3WDzMxMJSUl6euvv1aDBg301FNPub+jXLGSQABVFwkEULaKTiA+b3Cn1+bq9OO7XpurKqkyLQx7w26VHQJQ5cwK4+8FUBl4nbc5FlECAADLqkwFAgCAqsKb2zj/rEggAAAwqBKLA6s4WhgAAMAyKhAAABjQwjBHAgEAgAG7MMzRwgAAAJZRgQAAwKC0sgP4AyCBAADAwCVaGGZoYQAAAMuoQAAAYFDKgyBMkUAAAGBQSgvDFAkEAAAGrIEwxxoIAABgGRUIAAAM2MZpjgQCAAADWhjmaGEAAADLqEAAAGBAC8McCQQAAAYkEOZoYQAAAMuoQAAAYMAiSnMkEAAAGJSSP5iihQEAACyjAgEAgAHvwjBHAgEAgAEv4zRHAgEAgAHbOM2xBgIAAFhGBQIAAINSH9ZAmCGBAADAgDUQ5mhhAAAAy6hAAABgwCJKcyQQAAAY8CRKc7QwAACAZVQgAAAw4EmU5kggAAAwYBeGOVoYAADAMioQAAAYsIjSHBUIAAAMSr14WLF+/XrddtttioyMlI+Pj959912P6wMHDpSPj4/H0aNHD48xR48eVb9+/WS321W7dm0NGjRIJ0+e9BizZcsWdenSRdWrV1fDhg01ZcoUi5GSQAAAcAGXFw8rCgsL1a5dO82ePfs3x/To0UMHDx50H2+88YbH9X79+mn79u1KT0/X8uXLtX79eg0ZMsR9vaCgQLGxsWrcuLGys7M1depUTZgwQS+99JKlWGlhAABQRfTs2VM9e/a86Bibzabw8PAyr+3YsUOrVq3S5s2b1alTJ0nS888/r1tvvVXPPfecIiMjtXDhQhUXF2vevHkKCAhQq1atlJOTo3//+98eiYYZKhAAABiU+njvKCoqUkFBgcdRVFR0ybFlZmYqNDRUzZs317Bhw3TkyBH3taysLNWuXdudPEhSTEyMfH199dlnn7nHdO3aVQEBAe4xcXFx2rlzp44dO1buOEggAAAw8OYaiNTUVAUHB3scqamplxRXjx499PrrrysjI0PPPvus1q1bp549e+rs2bOSJKfTqdDQUI97qlWrppCQEDmdTveYsLAwjzHnP58fUx60MAAAqEApKSkaNWqUxzmbzXZJc/Xt29f9c5s2bdS2bVs1bdpUmZmZ6t69+++K0yoSCAAADLz5Mi2bzXbJCYOZK664QvXq1dOuXbvUvXt3hYeHKy8vz2PMmTNndPToUfe6ifDwcOXm5nqMOf/5t9ZWlIUWBgAABi4f7x0V6ccff9SRI0cUEREhSXI4HMrPz1d2drZ7zNq1a1VaWqro6Gj3mPXr16ukpMQ9Jj09Xc2bN1edOnXK/d0kEAAAVBEnT55UTk6OcnJyJEl79+5VTk6O9u3bp5MnT2r06NHauHGjvv/+e2VkZOiOO+5Qs2bNFBcXJ0lq2bKlevTooUceeUSbNm3Sp59+quHDh6tv376KjIyUJD3wwAMKCAjQoEGDtH37di1evFgzZsy4oM1ihhYGAAAG3mxhWPH555+rW7du7s/n/6GekJCgF154QVu2bNH8+fOVn5+vyMhIxcbG6umnn/ZokSxcuFDDhw9X9+7d5evrq969e2vmzJnu68HBwVqzZo0SExPVsWNH1atXT+PGjbO0hVOSfFwuV5V4Z0iNGo0rOwSgyplWr0tlhwBUSUP3L6jQ+Wc1fNBrcw2v4FgrCy0MAABgGS0MAAAMqkRpvoojgQAAwIC3cZojgQAAwKCyFlH+kbAGAgAAWEYFAgAAAyoQ5kggAAAwYBGlOVoYAADAMioQAAAYsAvDHAkEAAAGrIEwRwsDAABYRgUCAAADFlGaI4EAAMCglBTCFC0MAABgGRUIAAAMWERpjgQCAAADGhjmSCAAADCgAmGONRAAAMAyKhAAABjwJEpzJBAAABiwjdMcLQwAAGAZFQgAAAyoP5gjgQAAwIBdGOZoYQAAAMuoQAAAYMAiSnMkEAAAGJA+mKOFAQAALKMCAQCAAYsozZFAAABgwBoIcyQQAAAYkD6YYw0EAACwjAoEAAAGrIEwRwIBAICBiyaGKVoYAADAMioQAAAY0MIwRwIBAIAB2zjN0cIAAACWUYEAAMCA+oM5KhB/ANdff63eeutV7dmzSadO/aDbbou96Pg77uih5csXaN++L5Sbu02ZmcsUE9O1wuO8++5blZOToWPHdmrz5tWKi+vmvlatWjU988zj2rx5tQ4f3qE9ezbplVf+rYiI0AqPC39OEdHN1WPeKPX//HkN3b9Al8d1vOj4yM4tNXT/gguOGvWDKzTOK+KvVZ+Pp2jwd/N0b3qqGnVr53G9U9Ld6vPxFA3a+Yoe2vqiei16XKHtm1ZoTDBXKpfXDivWr1+v2267TZGRkfLx8dG7777rcd3lcmncuHGKiIhQjRo1FBMTo++++85jzNGjR9WvXz/Z7XbVrl1bgwYN0smTJz3GbNmyRV26dFH16tXVsGFDTZkyxfLviATiDyAoKFBbt+7QyJFPlWv8DTdcq7Vr/6u77hqo667rpXXrNujtt19Vu3atLjmGLl0665tvPvnN6507d9T8+c9r/vwl6tw5Xh98sEZLlrykqKirJEmBgTXUvn1rTZ48Uw5HvPr2/ZuuuuoKLV366iXHhL+2ajVsOrJjn/47dr6l+97o+pjmd0h0H6cOF1xyDJGdW6rfhmm/eT2s45WKmZWob95cp7d6jtX3q7MV90qS6jRv4B6Tv/egPnlqvpbckqJ3e0/SiR8PK35hsqqH1LrkuPDHVVhYqHbt2mn27NllXp8yZYpmzpypuXPn6rPPPlNQUJDi4uJ0+vRp95h+/fpp+/btSk9P1/Lly7V+/XoNGTLEfb2goECxsbFq3LixsrOzNXXqVE2YMEEvvfSSpVhpYfwBrFmTqTVrMss9fvToSR6fx4+fql69YnXrrd311VfbJUk+Pj76xz+GadCgBxQWVl/ffbdHkyc/r2XLPrykGBMTH9KaNes0bdqLkqRJk/5X3bvfoKFDE/Too0+qoOCEevV60OOepKRx+uSTD9SwYaT27z9wSd+Lv679mVu0P3OL5ftOHSlQccHPZV/08dHVf++llg90U2BobeXvOagvZryrPR9uvqQY2wyK0/7MLfrqxRWSpM3PvaUGXVqrdcIt+u8Tr0mSdr2b5XHPhkkL1fL+m1S3ZSP99On2S/pe/H6VtQujZ8+e6tmzZ5nXXC6Xpk+frrFjx+qOO+6QJL3++usKCwvTu+++q759+2rHjh1atWqVNm/erE6dOkmSnn/+ed1666167rnnFBkZqYULF6q4uFjz5s1TQECAWrVqpZycHP373//2SDTMUIH4C/Dx8VGtWkE6duy4+9zo0Ynq16+3Rox4Qh06xOj551/VvHnTdMMN0Zf0HdHRHfTxx54VivT09YqO7vCb99jttVRaWqr8/Ev/N0DAqntX/VP9P5+lXguTFd7pSo9rHYbfpqt636D1T7ymxd2TtfWVVbp5xjBFdG5xSd8V1qGZfvxkm8e5/eu2KKxjszLH+/r7KapfNxUdL9SRr3+4pO+Ed7i8+J+ioiIVFBR4HEVFRZZj2rt3r5xOp2JiYtzngoODFR0draysc4loVlaWateu7U4eJCkmJka+vr767LPP3GO6du2qgIAA95i4uDjt3LlTx44dK3c8VCD+ApKShigoKEhvv71ckhQQEKAxYxIVH99Pn332hSTp++/367rrrtHgwf30ySefWf6OsLD6yss77HEuL++wwsLqlzneZrPpmWdStGTJ+zpx4mSZYwBvKszL17rH5+nQlj3yC/BXy/tv0m1LntSy2yfo8Lbv5RtQTVcPv13L75+s3C92SZJ27juk8GuaK6rfzTq48RvL3xlYv/YFLZJThwsUWL+2x7lG3dvrltnDVa1GgH7Oy9fyfs/q9DH+XlQmb1YgUlNTNXHiRI9z48eP14QJEyzN43Q6JUlhYWEe58PCwtzXnE6nQkM915ZVq1ZNISEhHmOaNGlywRznr9WpU6dc8Xg9gdi/f7/Gjx+vefPm/eaYoqKiC7Ivl8slHx8fb4fzl9enzx164omRuvfewTp06IgkqWnTxgoKCtTy5Qs8xgYE+LtbHJJ06NDX7p/9/PxkswV4nHvjjWV69NEnLcdUrVo1LVgwWz4+Ppd0P3Apju85qON7Dro/52Z/J3vjULUd3ENrR85V8OVh8g+srl6LHve4z9e/mg5v/979edA3r7h/9vHzlV9ANY9z377zqbs9UV4HNuzQ0h5Pqnqdmmr5QDfdMme43rl9gk4foTr3Z5CSkqJRo0Z5nLPZbJUUjfd4PYE4evSo5s+ff9EEoqxszM/PLn//2t4O5y/t3ntv05w5z6pfv7/r448/dZ+vWTNIknTXXQ/pwAGnxz3FxcXun6Ojf+nDXXvt1XrmmccVG9vHfe7XlYPc3EMKDa3nMVdoaD3l5h7yOFetWjUtXDhbjRpdpp4976f6gEqVl7NH4decW+jrH1hdkvThwOdU6PQs454tKnH/vLTHL0lvWPumin6ir96/75/uc8UnTrl//vlQvmrUs3vMVaOeXT8fyvc4d+ZUkQq+z1XB97nK+3K37l//nFr2vVFfzv7g9/0Bccm8+S4Mm83mlYQhPDxckpSbm6uIiAj3+dzcXLVv3949Ji8vz+O+M2fO6OjRo+77w8PDlZub6zHm/OfzY8rDcgLx/vvvX/T6nj17TOcoKxsLDW1tNRRcxH333a65c6dqwIDhWrVqrce1HTu+0+nTp9WwYeRF2xV79vzSg73ssgidOXPG49yvffbZF7rppus1a9YviWP37l3cLRLpl+ShadMm6tGjr44ezb/EPx3gHfWiGunnvHxJ0rHvftKZ08WqGVn3ou2Kgu9/+X+8NcND5Dpz1uPcr+V+sUuXXd9KW19d7T7XoEtr5Wbvunhgvj7yC/Av/x8EXlcVH2XdpEkThYeHKyMjw50wFBQU6LPPPtOwYcMkSQ6HQ/n5+crOzlbHjue2Nq9du1alpaWKjo52j3nyySdVUlIif/9z/3eWnp6u5s2bl7t9IV1CAnHnnXfKx8dHLtdvZ2dmrYiysjHaF78tKChQTZte7v58+eUN1bZtlI4dy9f+/Qc0adIYRUaGa/Dgc0lZnz536OWX/1ePPTZRmzfnuNchnDp1WgUFJ3TyZKGmT39ZU6aMk6+vrzZs2KzgYLscjk4qKDihhQvfthzj7Nmvac2axfqf/3lEK1eu1b333qYOHdooMfFcObhatWpatOgFXX11a91998Py8/Nzx3X0aL5KSkouNj1wgWqBNgVf/ksv2N6wvupGNVJRfqFOHjiia5PvU1B4HX2cdG5nUJtBcTqx/5COfvuT/Gz+atn3JkVe30or+j0rSSopPK2vXvpQ141/UD6+vnJu3qmAWoEK73Slik+e1rdv/ddyjFtfXa3blz6ptkN6al9Gjprd7lD9tldo3ePnEu1qNWzq8Ogd+n5Ntn7Oy1f1kFpqnXCLgsLqaPcK62uR8Md38uRJ7dr1S4K5d+9e5eTkKCQkRI0aNdLIkSP1zDPP6Morr1STJk301FNPKTIyUnfeeackqWXLlurRo4ceeeQRzZ07VyUlJRo+fLj69u2ryMhISdIDDzygiRMnatCgQUpOTta2bds0Y8YMTZv221uSy2I5gYiIiNCcOXPcW0iMcnJy3FkPvKNDh7Zas2ax+/OUKeMkSf/5z1INGfKYwsND1bBhpPv6ww/fL39/f82Y8YxmzHjGff78eEmaOPE5HT58RKNH/11NmjRSfn6BcnK2acqUsvcem9m4MVsDBz6q8eMf08SJo7Vr1/e6774h+vrrbyVJkZHh7gdgbdq0yuPe2Ng++u9/N17S9+KvK7TtFbp96S/thOvGn9smvHPpen086iUFhdVWrct+aav5+VeT46l+CgqvozOninRkx34tvz9VB7J2uMdsnvqWTh85oasTb5O90SAVFxTq0LYf9OWs9y4pxtzs75QxYo6uHX2vosfcp+PfO7V68DQd2/mjJMlVWqraTSMU99L/qHqdWjqdf1J5X+3Re/c8o2Pf/nRJ3wnvKL3IvyRXpM8//1zduv3yEL7z1fqEhASlpaVpzJgxKiws1JAhQ5Sfn68bbrhBq1atUvXq1d33LFy4UMOHD1f37t3l6+ur3r17a+bMme7rwcHBWrNmjRITE9WxY0fVq1dP48aNs7SFU5J8XBcrJZTh9ttvV/v27TVp0qQyr3/11Ve6+uqrVVpqrQBUo0ZjS+OBv4Jp9bpUdghAlTR0/wLzQb/Dg43v9tpcC354x2tzVSWWKxCjR49WYWHhb15v1qyZPv74498VFAAAqNosJxBdulz834iCgoJ04403XnJAAABUNl7nbY4HSQEAYODNbZx/VjzKGgAAWEYFAgAAg6r4HIiqhgQCAAAD1kCYI4EAAMCANRDmWAMBAAAsowIBAIABayDMkUAAAGBg8SHNf0m0MAAAgGVUIAAAMGAXhjkSCAAADFgDYY4WBgAAsIwKBAAABjwHwhwJBAAABqyBMEcLAwAAWEYFAgAAA54DYY4EAgAAA3ZhmCOBAADAgEWU5lgDAQAALKMCAQCAAbswzJFAAABgwCJKc7QwAACAZVQgAAAwoIVhjgQCAAADdmGYo4UBAAAsowIBAIBBKYsoTZFAAABgQPpgjhYGAACwjAoEAAAG7MIwRwIBAIABCYQ5EggAAAx4EqU51kAAAADLqEAAAGBAC8McCQQAAAY8idIcLQwAAGAZCQQAAAYul8trhxUTJkyQj4+Px9GiRQv39dOnTysxMVF169ZVzZo11bt3b+Xm5nrMsW/fPsXHxyswMFChoaEaPXq0zpw545Xfy6/RwgAAwKAy10C0atVKH330kftztWq//KM6KSlJK1as0NKlSxUcHKzhw4fr7rvv1qeffipJOnv2rOLj4xUeHq4NGzbo4MGDGjBggPz9/fWvf/3Lq3GSQAAAUIVUq1ZN4eHhF5w/fvy4Xn31VS1atEg333yzJOm1115Ty5YttXHjRnXu3Flr1qzR119/rY8++khhYWFq3769nn76aSUnJ2vChAkKCAjwWpy0MAAAMKisFoYkfffdd4qMjNQVV1yhfv36ad++fZKk7OxslZSUKCYmxj22RYsWatSokbKysiRJWVlZatOmjcLCwtxj4uLiVFBQoO3bt//O34onKhAAABh4s4VRVFSkoqIij3M2m002m+2CsdHR0UpLS1Pz5s118OBBTZw4UV26dNG2bdvkdDoVEBCg2rVre9wTFhYmp9MpSXI6nR7Jw/nr5695ExUIAAAqUGpqqoKDgz2O1NTUMsf27NlT9957r9q2bau4uDh9+OGHys/P15IlS/6PozZHAgEAgIHLi/9JSUnR8ePHPY6UlJRyxVG7dm1dddVV2rVrl8LDw1VcXKz8/HyPMbm5ue41E+Hh4Rfsyjj/uax1Fb8HCQQAAAalLpfXDpvNJrvd7nGU1b4oy8mTJ7V7925FRESoY8eO8vf3V0ZGhvv6zp07tW/fPjkcDkmSw+HQ1q1blZeX5x6Tnp4uu92uqKgor/6OWAMBAIBBZT2J8rHHHtNtt92mxo0b68CBAxo/frz8/Px0//33Kzg4WIMGDdKoUaMUEhIiu92uESNGyOFwqHPnzpKk2NhYRUVFqX///poyZYqcTqfGjh2rxMTEcict5UUCAQBAFfHjjz/q/vvv15EjR1S/fn3dcMMN2rhxo+rXry9JmjZtmnx9fdW7d28VFRUpLi5Oc+bMcd/v5+en5cuXa9iwYXI4HAoKClJCQoImTZrk9Vh9XFXknaU1ajSu7BCAKmdavS6VHQJQJQ3dv6BC528Zeq3X5tqRt8lrc1UlVCAAADDgZVrmWEQJAAAsowIBAIBBadXo7ldpJBAAABjQwjBHCwMAAFhGBQIAAANaGOZIIAAAMKCFYY4WBgAAsIwKBAAABi5XaWWHUOWRQAAAYFBKC8MUCQQAAAZV5C0PVRprIAAAgGVUIAAAMKCFYY4EAgAAA1oY5mhhAAAAy6hAAABgwJMozZFAAABgwJMozdHCAAAAllGBAADAgEWU5kggAAAwYBunOVoYAADAMioQAAAY0MIwRwIBAIAB2zjNkUAAAGBABcIcayAAAIBlVCAAADBgF4Y5EggAAAxoYZijhQEAACyjAgEAgAG7MMyRQAAAYMDLtMzRwgAAAJZRgQAAwIAWhjkSCAAADNiFYY4WBgAAsIwKBAAABiyiNEcCAQCAAS0McyQQAAAYkECYYw0EAACwjAoEAAAG1B/M+bio0+BXioqKlJqaqpSUFNlstsoOB6gS+HsBXIgEAh4KCgoUHBys48ePy263V3Y4QJXA3wvgQqyBAAAAlpFAAAAAy0ggAACAZSQQ8GCz2TR+/HgWigG/wt8L4EIsogQAAJZRgQAAAJaRQAAAAMtIIAAAgGUkEAAAwDISCLjNnj1bl19+uapXr67o6Ght2rSpskMCKtX69et12223KTIyUj4+Pnr33XcrOySgyiCBgCRp8eLFGjVqlMaPH68vvvhC7dq1U1xcnPLy8io7NKDSFBYWql27dpo9e3ZlhwJUOWzjhCQpOjpa11xzjWbNmiVJKi0tVcOGDTVixAg9/vjjlRwdUPl8fHy0bNky3XnnnZUdClAlUIGAiouLlZ2drZiYGPc5X19fxcTEKCsrqxIjAwBUVSQQ0OHDh3X27FmFhYV5nA8LC5PT6aykqAAAVRkJBAAAsIwEAqpXr578/PyUm5vrcT43N1fh4eGVFBUAoCojgYACAgLUsWNHZWRkuM+VlpYqIyNDDoejEiMDAFRV1So7AFQNo0aNUkJCgjp16qRrr71W06dPV2FhoR566KHKDg2oNCdPntSuXbvcn/fu3aucnByFhISoUaNGlRgZUPnYxgm3WbNmaerUqXI6nWrfvr1mzpyp6Ojoyg4LqDSZmZnq1q3bBecTEhKUlpb2fx8QUIWQQAAAAMtYAwEAACwjgQAAAJaRQAAAAMtIIAAAgGUkEAAAwDISCAAAYBkJBAAAsIwEAgAAWEYCAQAALCOBAAAAlpFAAAAAy0ggAACAZf8PU8e/QuJcNNcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5efc516-1112-4a7c-9202-bccdb1446b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Logistic Regression\n",
      "Recall ---> 0.92\n",
      "Precision ---> 0.98\n",
      "Accuracy ---> 0.97\n"
     ]
    }
   ],
   "source": [
    "all_metrics(y_test, y_pred, name='Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb48e4bd-e527-4136-b793-02d409f769b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b41d4ea-2863-4a35-9c66-b040a3643b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_svc = LinearSVC(dual='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a6b0ed8-10a8-438f-9ca8-1771323778a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C':[0.1, 1, 2, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67018039-9e07-4e12-950e-3bcf8c6640e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lin_svc, param_grid, n_jobs=10, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3325536-43c2-4609-adb6-706dda2bd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LinearSVC(), n_jobs=10,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 2, 5]}, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LinearSVC(), n_jobs=10,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 2, 5]}, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LinearSVC</label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(), n_jobs=10,\n",
       "             param_grid={'C': [0.1, 1, 2, 5]}, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f85f4d8-34ae-46d5-afcf-2c66cdf0c198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ac9d7ce-e1fb-4d15-bd89-297dac38201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c19298ec-7fd1-4966-bab0-3f406675bce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearSVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eb4b36b-c930-489e-8930-c46eb9ae801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45707d3c-cfe9-43e2-9e95-b1adfda51867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3848\n",
      "           1       0.98      0.96      0.97      1569\n",
      "\n",
      "    accuracy                           0.98      5417\n",
      "   macro avg       0.98      0.98      0.98      5417\n",
      "weighted avg       0.98      0.98      0.98      5417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "405de234-71d4-4191-8e42-d768e1b8d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Linear SVM Classifer\n",
      "Recall ---> 0.96\n",
      "Precision ---> 0.98\n",
      "Accuracy ---> 0.98\n"
     ]
    }
   ],
   "source": [
    "all_metrics(y_test, y_pred, name='Linear SVM Classifer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5adb6934-7341-4949-9d68-dc4f5b095b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "059a0858-4c81-4e73-9fe9-c54f856398bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(best_svm, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "097f8797-fb85-4267-af62-6817402854cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(vectorizer, 'vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce94c7-4cb6-4049-aa34-863f0c5ff479",
   "metadata": {},
   "source": [
    "### Using BERT Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1ca209b-bca2-4bd3-8c91-2031c0ec0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c97a95f0-536b-4a08-acd5-356a9b728fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "789a8644-f8d4-4137-9a4d-2fc02beccb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 3105, 14739, 1011, 6207, 1011, 26354, 2470, 2415, 4180, 1011, 3091, 1024, 27908, 2575, 6207, 1011, 26354, 2470, 2415, 2149, 1002, 2184, 2454, 4101, 6957, 6207, 3274, 4297, 1012, 2820, 3001, 2671, 2120, 2118, 5264, 1010, 2284, 5264, 1010, 2559, 1024, 3026, 4613, 7155, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 3144, 4018, 2470, 11532, 15078, 15397, 1010, 2164, 3019, 2653, 6364, 1008, 1008, 2394, 1008, 1008, 1008, 1008, 2822, 1008, 1008, 7778, 2653, 11643, 1012, 3716, 2110, 1011, 1997, 1011, 1996, 1011, 2396, 13931, 1011, 2241, 1050, 1011, 13250, 2653, 4275, 1010, 17053, 2653, 4275, 1010, 2112, 1011, 1997, 1011, 4613, 2653, 4275, 3223, 1012, 3793, 1011, 1011, 4613, 2622, 3003, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 3144, 4018, 2470, 11532, 11532, 2048, 2206, 2752, 1024, 15078, 15397, 1010, 2164, 3019, 2653, 11968, 7741, 1010, 16105, 9289, 7809, 2640, 1010, 7778, 2653, 11643, 1025, 3793, 19204, 3989, 3671, 3989, 1025, 4013, 6499, 14808, 4106, 1012, 6937, 3716, 6887, 17175, 6483, 1010, 20231, 1010, 28081, 2822, 3223, 1012, 3716, 6490, 26664, 2015, 1013, 4613, 4742, 6364, 16166, 1012, 5347, 8065, 2560, 1016, 1018, 2086, 7882, 2147, 3325, 1010, 4087, 23794, 3014, 2560, 1019, 1021, 2086, 4654, 4842, 9013, 2278, 1041, 1012, 2844, 4007, 3330, 4813, 1010, 2164, 2640, 7375, 1010, 4031, 3989, 3223, 4460, 1012, 3716, 1039, 1010, 1039, 1009, 1009, 19998, 6871, 1012, 19998, 1004, 1039, 20273, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 1011, 2559, 5281, 19998, 1004, 1039, 20273, 1010, 9544, 8231, 2204, 3068, 3325, 1010, 3693, 2149, 4911, 2047, 28750, 1012, 2844, 3716, 19998, 5906, 1006, 21624, 2015, 1010, 4957, 2545, 1010, 2191, 1010, 1060, 1011, 3645, 1010, 1041, 1011, 6097, 1010, 1012, 1012, 1012, 1007, 3325, 13523, 20470, 3223, 1012, 3103, 13773, 8425, 3325, 5056, 1012, 28547, 2625, 2048, 2086, 3068, 3325, 2342, 6611, 1012, 4460, 2421, 8290, 6529, 2120, 2118, 5264, 1010, 6207, 1005, 1055, 4613, 2470, 4031, 3989, 4073, 2284, 2452, 8743, 5740, 1010, 2662, 1012, 5270, 4772, 2248, 4045, 1013, 3330, 9281, 6628, 1012, 6666, 2421, 7587, 6975, 10300, 1010, 3847, 28768, 1010, 18344, 11727, 1012, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 1035, 4604, 3143, 13746, 1010, 4372, 20464, 18606, 3167, 3327, 2015, 1010, 15644, 1010, 3325, 3967, 7026, 2193, 1024, 2720, 3744, 1011, 12776, 3393, 19892, 4609, 2415, 3208, 6207, 1011, 26354, 2470, 2415, 1010, 2820, 3001, 2671, 21863, 2290, 14163, 2072, 6358, 2290, 11134, 1010, 5264, 5709, 14526, 10093, 1024, 1006, 3515, 1007, 6255, 2475, 1011, 3515, 2581, 2487, 6904, 2595, 1024, 1006, 3515, 1007, 6255, 2575, 1011, 4278, 2629, 10373, 1024, 1046, 6216, 19892, 4609, 1030, 26354, 1012, 16371, 2015, 1012, 22214, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(df['text'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6070e775-53bc-4926-be6b-f3e0b2a35513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # Get the embeddings of the [CLS] token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc67146b-1593-47ad-b8f4-bcb4074089ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9549603f-c8e3-4111-abd2-f4f6aef82e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_in_batches(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_embeddings = encode_batch(batch)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)  # Stack all the embeddings vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "842eb2e0-0fbd-4fe5-aabc-b13be1cdadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8f4277d-b85e-49af-bb4f-dbabc9e7d1fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m X_test_embeddings \u001b[38;5;241m=\u001b[39m process_in_batches(X_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m, in \u001b[0;36mprocess_in_batches\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size):\n\u001b[1;32m      4\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 5\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(embeddings)\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36mencode_batch\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1137\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1137\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1150\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:690\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    679\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    680\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    681\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m         output_attentions,\n\u001b[1;32m    688\u001b[0m     )\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:580\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:519\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    502\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    510\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    511\u001b[0m         hidden_states,\n\u001b[1;32m    512\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m         output_attentions,\n\u001b[1;32m    518\u001b[0m     )\n\u001b[0;32m--> 519\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:463\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    461\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    462\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 463\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_embeddings = process_in_batches(X_train, batch_size=batch_size)\n",
    "X_test_embeddings = process_in_batches(X_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0f904-a9c6-4c40-bf3c-a51af0d556bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
