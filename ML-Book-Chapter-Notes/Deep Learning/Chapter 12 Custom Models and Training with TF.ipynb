{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc0f793-e6f4-4593-90b9-b9903a45ee87",
   "metadata": {},
   "source": [
    "# Custom Models and Training with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a255fd8-df41-4352-8787-8ffbd2b1b36f",
   "metadata": {},
   "source": [
    "The Keras API and tf.data library is used for about 95% of the time. However, if you need custom or specific use cases, you can do them using the lower level python API from Tensorflow. This can be used for custom loss functions, metrics, layers, models, and so on. This can be useful in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3551e2e-03f7-4dcc-af2b-a3afe1b5d602",
   "metadata": {},
   "source": [
    "## Using TF like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09050088-af5f-48e2-b871-3b45c0bff062",
   "metadata": {},
   "source": [
    "Tensorflow is built around <b><i>Tensors</i></b>. A tensor is very similar to a numpy ndarray: it is usually a multidimensional array, but it can also hold a scaler. These tensors are important when creating custom utilities for tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb872e2-e68b-4ee2-b64f-26fd12f0f342",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03137717-e2eb-4503-b804-b9f49ff006b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 16:49:38.426895: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-06 16:49:38.437128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736203778.449667   11444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736203778.453342   11444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 16:49:38.465345: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660d3a75-13db-4312-b834-89a847a6fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736203779.961249   11444 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1.,2.,3.], [4.,5.,6.]]) # Matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819d3a74-9360-460f-8251-cccb58b5fba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf172de-60d1-4671-8428-8423b0a1c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be51f6be-14f6-408a-915e-8d5d663b467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ff6243-2184-4d11-896c-2d83ade63c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e7a5e2-2114-4621-a440-109db478be78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce724460-575f-423a-a288-320963437575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da7e3a5-00e2-4e11-86d8-d4e55d08299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scaler in a tensor\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f54d7-fe0c-43ed-8022-d3b204cd58f0",
   "metadata": {},
   "source": [
    "### Tensors and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f26ec9-a698-4e5f-bf8b-61268abc585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b5fada-3329-4dee-9946-02b3f3d28e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36895c9b-5d2a-4a02-a673-c09115aa9869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760e5977-f986-4191-94a6-8d10fd2fa24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fed61a-23f3-4fa7-8e68-1c9d549a49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08eb7426-69a7-4bb4-bf33-0e3864c88a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485720da-4d84-4c4a-b822-d5cbc47d005d",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea465b3a-d62e-4e8e-8948-556282894b3c",
   "metadata": {},
   "source": [
    "By default TF will not perform type conversions automaticly because it can lead to problems when training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5536954-97eb-44d7-87ef-01400c9b21ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c63e81-76a0-41ce-820e-a44689f41403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=32.0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use tf.cast() if you really need to get around this\n",
    "t2 = tf.constant(30.0, dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cd9df-a381-4d23-81c4-768f506099fa",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea066eec-0859-4117-b8d3-a171b46d3859",
   "metadata": {},
   "source": [
    "Tensors are immutable. So if you need to change the values in a tensor, use a <b>TF Variable instead</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2710da12-fc72-4142-b622-2714a7d639f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1.,2.,3.], [4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654f2559-fb8f-45e8-a9bb-6e3a39f726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc1f66-327b-4d37-a76a-6f2718cd4058",
   "metadata": {},
   "source": [
    "A variable works just like a tensor and can use the same operations. However a variable can also be modified, unlike a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb029ef-67e1-427c-8d72-5e9db89afdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fc04d6a-e0fe-4136-ba62-f1c75d7bf543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0,1].assign(42)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475f50fd-a7ae-4faf-949f-84ce251db692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Direct assignment doesn't work\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m7.\u001b[39m, \u001b[38;5;241m8.\u001b[39m, \u001b[38;5;241m9.\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "### Direct assignment doesn't work\n",
    "v[1] = [7., 8., 9.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4d691-7aff-4d5f-8032-0f08b6765c78",
   "metadata": {},
   "source": [
    "### Other Data structures:\n",
    "- Sparse Tensors\n",
    "- Tensor Arrays\n",
    "- Ragged Tensors\n",
    "- String Tensors\n",
    "- Sets\n",
    "- Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bcbb-be1a-4328-9f88-71d96f13bf58",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7de9a1-5f39-4f92-bd5d-607b541f260a",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9f30f-7d35-4e7a-8e7a-4faea3ead5ab",
   "metadata": {},
   "source": [
    "To make a custom loss function, just make a funciton that can take y_true and y_pred. Then have it make an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c88d977-c5de-4d81-afdc-1c48e582de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Huber loss \n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "### Should only use TensorFlow operations to make it easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b1a55b-1088-4d7f-b842-72368d9a2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/Desktop/env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – loads, splits and scales the California housing dataset, then\n",
    "#              creates a simple Keras model\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9437ac-5713-4a8a-a33b-e338dae2a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just add the function to the loss parameter\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1ef36e-b3bb-4fb6-9c06-57ccf1557d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736203794.085334   11509 service.cc:148] XLA service 0x77ae78019a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736203794.085351   11509 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-01-06 16:49:54.106875: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1736203794.146654   11509 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.9070 - mae: 1.3159  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736203794.345920   11509 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7494 - mae: 1.1371 - val_loss: 0.3474 - val_mae: 0.6522\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2607 - mae: 0.5681 - val_loss: 0.2553 - val_mae: 0.5383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77af27f2bda0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050fec1-cba1-4f2a-8689-f870c2419c5c",
   "metadata": {},
   "source": [
    "### Saving and Loading Models that contain Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed5371e4-d930-4223-8288-3dbcaebef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "### With custom loss saving is the same\n",
    "model.save(\"my_model_with_a_custom_loss.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d1f437-e8b4-4e8d-a8ff-ab8ad687403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading is different, you need to map the loss to the original function\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeabc623-13f8-44d8-a404-3c2ce3c0e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to add extra hyperparameters in the custom loss\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = tf.abs(error) - 0.5\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a691641e-03fe-4374-9f96-24ca2f0d81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "891409f0-367e-4b0e-b1f1-b0433e4e3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### When you save this model, the threshold will not be saved and needs to be mapped\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18df055-f877-46b5-af92-73280e1721f9",
   "metadata": {},
   "source": [
    "You can solve this by creating a subclass of tf.keras.losses.Loss class and implementing its get_config() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38abd564-27c8-4c79-8f3b-3b92c3bddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    \"Huber Loss object class\"\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_error = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_error, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feaeaefd-20e9-43e8-b2cb-5da0386f24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/Desktop/env/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 11 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(2.0), optimizer='nadam')\n",
    "model.save(\"my_model_with_a_custom_loss.keras\")\n",
    "### Threshold will be saved now when loaded\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201b086-a391-45b3-aedd-a35dc8f01a84",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "312d4304-61dc-41fd-8631-0e59eff2dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equivalent to keras.activations.softplus()\n",
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "## Equivalent to keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "## Equivalent to keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "## Equivalent to keras.constraints.nonneg()\n",
    "def my_positive_weights(weights):  # Return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weigths < 0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc756156-740f-4d11-b5a9-fd0d2f2dad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add custom components to layer\n",
    "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
    "                             kernel_initializer=my_glorot_initializer,\n",
    "                             kernel_regularizer=my_l1_regularizer,\n",
    "                             kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e38cce-f60d-4c15-8d4e-69dd85c9dc9a",
   "metadata": {},
   "source": [
    "If the custom component has a hyperparameter that needs to be saved, use subclassing to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d95f1ac-29d2-4462-bf37-90cd58f11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c81c3-83b6-4433-b7ad-fb1d6f143846",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15434c-5caa-41a3-9a32-c812740a9ce9",
   "metadata": {},
   "source": [
    "<b>The Difference Between losses and metrics</b>\n",
    "- <b>Losses</b> like cross entropy are used by gradient descent to <b>train</b> a model, so they must be differentable and not have zero gradients everywhere. They are not supposed to be easily interpretable by humans.\n",
    "- <b>Metrics</b> are used by humans to <b>evaluate</b> a model. They must be easily interpretable, and can be non-differentable and have zero gradients everywhere<br><br>\n",
    "In most cases, a custom metrics is built the same way as a custom loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8281e321-0bce-4257-8e14-0a3748bb06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the huber loss as a metric\n",
    "model.compile(loss='mse', optimizer='nadam', metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd57a4-e4f7-4933-a417-69bdb560bd4a",
   "metadata": {},
   "source": [
    "Keras calculates the metric on each batch then outputs the mean of the metric after each epoch. However in some cases like with Precision, you don't want a mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a57dfbfe-72ca-4e1e-84bd-ad02c594e668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.800000011920929>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0,1,1,1,0,1,0,1], [1,1,0,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6242526a-e125-4986-bd1b-e6512c75366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,0,0,1,0,1,1], [1,0,1,1,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b4145-be86-47a2-bd2f-6d209ddcc9a1",
   "metadata": {},
   "source": [
    "Precision is a <b>streaming or stateful metric</b>. This means that the metric is gradually updated batch after batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90bf5baf-8a0f-4784-81ea-aae640fcf1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e268f4cc-9f24-4fae-b76f-3f121263a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fb19f04-c92f-404f-af88-b6653b050b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state() # Both variables get set to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5acd2da9-7b9b-497e-a42f-8f1a8f3a27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If you want to create your own custom streaming metric, create a subclass.\n",
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    Streaming HuberMetric\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer='zeros')  ## Create variable to track sum of all Huber losses\n",
    "        self.count = self.add_weight(\"count\", initializer='zeros')  ## Create variable to track number of instances\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b213f6e-fd9d-4b54-ac5e-ee155c9f8fe6",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd5b4-c4c7-43c2-be37-14e642bc6111",
   "metadata": {},
   "source": [
    "Occasionally you will want to build an architecture that contains an exotic layer that Tensorflow doesn't provide or you have a repetitive architecture where a particular block of layers is repeated many times and you want to just think of the blocks as one layer. For these cases, you build a custom layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfd299ba-5ebe-4f04-9034-cd9572000c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For layers without weights just use Lambda\n",
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76591d6c-3a85-4646-9908-eb60aa81a329",
   "metadata": {},
   "source": [
    "This custom layer can be used just like any other layer. <br>\n",
    "To build a custom stateful layer(i.e. a layer with weigths), you need to create a subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5973b089-e580-47e7-a286-09c51685b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def built(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='zeros')\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\":self.units,\n",
    "               'activation': tf.keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8d2d37a-082f-4ff7-a846-6145b3837683",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Layer with multiple inputs (e.g. Concatenate)\n",
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X): ## X should be a tuple of all the inputs\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b7dbb-fad3-4ea5-a7a1-6090cc079969",
   "metadata": {},
   "source": [
    "If your layer needs a different behavior during training and during testing, like Dropout or BatchNormalization, then you must add a training argument to the call() method and use it to decide what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a552df3-ea8d-4538-80a5-81ac52ffd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=False):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d5d79-efac-423f-b93c-390f6fe7cfce",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1ae72-8505-4ebf-acb5-0306611b3509",
   "metadata": {},
   "source": [
    "An intro to this topic was in Chapter 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e67bc0-f9ca-42f1-8444-a8845f39e6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
