{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc0f793-e6f4-4593-90b9-b9903a45ee87",
   "metadata": {},
   "source": [
    "# Custom Models and Training with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a255fd8-df41-4352-8787-8ffbd2b1b36f",
   "metadata": {},
   "source": [
    "The Keras API and tf.data library is used for about 95% of the time. However, if you need custom or specific use cases, you can do them using the lower level python API from Tensorflow. This can be used for custom loss functions, metrics, layers, models, and so on. This can be useful in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3551e2e-03f7-4dcc-af2b-a3afe1b5d602",
   "metadata": {},
   "source": [
    "## Using TF like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09050088-af5f-48e2-b871-3b45c0bff062",
   "metadata": {},
   "source": [
    "Tensorflow is built around <b><i>Tensors</i></b>. A tensor is very similar to a numpy ndarray: it is usually a multidimensional array, but it can also hold a scaler. These tensors are important when creating custom utilities for tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb872e2-e68b-4ee2-b64f-26fd12f0f342",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03137717-e2eb-4503-b804-b9f49ff006b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 14:51:05.846769: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 14:51:05.855876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736369465.866835    8026 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736369465.870102    8026 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 14:51:05.881239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660d3a75-13db-4312-b834-89a847a6fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736369467.160312    8026 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1.,2.,3.], [4.,5.,6.]]) # Matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819d3a74-9360-460f-8251-cccb58b5fba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf172de-60d1-4671-8428-8423b0a1c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be51f6be-14f6-408a-915e-8d5d663b467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ff6243-2184-4d11-896c-2d83ade63c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e7a5e2-2114-4621-a440-109db478be78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce724460-575f-423a-a288-320963437575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da7e3a5-00e2-4e11-86d8-d4e55d08299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scaler in a tensor\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f54d7-fe0c-43ed-8022-d3b204cd58f0",
   "metadata": {},
   "source": [
    "### Tensors and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f26ec9-a698-4e5f-bf8b-61268abc585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b5fada-3329-4dee-9946-02b3f3d28e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36895c9b-5d2a-4a02-a673-c09115aa9869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760e5977-f986-4191-94a6-8d10fd2fa24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6fed61a-23f3-4fa7-8e68-1c9d549a49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08eb7426-69a7-4bb4-bf33-0e3864c88a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485720da-4d84-4c4a-b822-d5cbc47d005d",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea465b3a-d62e-4e8e-8948-556282894b3c",
   "metadata": {},
   "source": [
    "By default TF will not perform type conversions automaticly because it can lead to problems when training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5536954-97eb-44d7-87ef-01400c9b21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c63e81-76a0-41ce-820e-a44689f41403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=32.0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use tf.cast() if you really need to get around this\n",
    "t2 = tf.constant(30.0, dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3cd9df-a381-4d23-81c4-768f506099fa",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea066eec-0859-4117-b8d3-a171b46d3859",
   "metadata": {},
   "source": [
    "Tensors are immutable. So if you need to change the values in a tensor, use a <b>TF Variable instead</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2710da12-fc72-4142-b622-2714a7d639f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1.,2.,3.], [4.,5.,6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654f2559-fb8f-45e8-a9bb-6e3a39f726cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc1f66-327b-4d37-a76a-6f2718cd4058",
   "metadata": {},
   "source": [
    "A variable works just like a tensor and can use the same operations. However a variable can also be modified, unlike a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb029ef-67e1-427c-8d72-5e9db89afdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fc04d6a-e0fe-4136-ba62-f1c75d7bf543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0,1].assign(42)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "475f50fd-a7ae-4faf-949f-84ce251db692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Direct assignment doesn't work\n",
    "# v[1] = [7., 8., 9.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4d691-7aff-4d5f-8032-0f08b6765c78",
   "metadata": {},
   "source": [
    "### Other Data structures:\n",
    "- Sparse Tensors\n",
    "- Tensor Arrays\n",
    "- Ragged Tensors\n",
    "- String Tensors\n",
    "- Sets\n",
    "- Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9bcbb-be1a-4328-9f88-71d96f13bf58",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7de9a1-5f39-4f92-bd5d-607b541f260a",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9f30f-7d35-4e7a-8e7a-4faea3ead5ab",
   "metadata": {},
   "source": [
    "To make a custom loss function, just make a funciton that can take y_true and y_pred. Then have it make an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c88d977-c5de-4d81-afdc-1c48e582de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Huber loss \n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "### Should only use TensorFlow operations to make it easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b1a55b-1088-4d7f-b842-72368d9a2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/Desktop/env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extra code – loads, splits and scales the California housing dataset, then\n",
    "#              creates a simple Keras model\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be9437ac-5713-4a8a-a33b-e338dae2a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just add the function to the loss parameter\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1ef36e-b3bb-4fb6-9c06-57ccf1557d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736369468.641749    8089 service.cc:148] XLA service 0x742f40005420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736369468.641765    8089 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-01-08 14:51:08.663912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1736369468.706063    8089 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m198/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.9165 - mae: 1.3266  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736369468.908763    8089 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7494 - mae: 1.1371 - val_loss: 0.3474 - val_mae: 0.6522\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2607 - mae: 0.5681 - val_loss: 0.2553 - val_mae: 0.5383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7430363e1e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050fec1-cba1-4f2a-8689-f870c2419c5c",
   "metadata": {},
   "source": [
    "### Saving and Loading Models that contain Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed5371e4-d930-4223-8288-3dbcaebef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "### With custom loss saving is the same\n",
    "model.save(\"my_model_with_a_custom_loss.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7d1f437-e8b4-4e8d-a8ff-ab8ad687403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading is different, you need to map the loss to the original function\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeabc623-13f8-44d8-a404-3c2ce3c0e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you want to add extra hyperparameters in the custom loss\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = tf.abs(error) - 0.5\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a691641e-03fe-4374-9f96-24ca2f0d81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "891409f0-367e-4b0e-b1f1-b0433e4e3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### When you save this model, the threshold will not be saved and needs to be mapped\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18df055-f877-46b5-af92-73280e1721f9",
   "metadata": {},
   "source": [
    "You can solve this by creating a subclass of tf.keras.losses.Loss class and implementing its get_config() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38abd564-27c8-4c79-8f3b-3b92c3bddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    \"Huber Loss object class\"\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_error = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold ** 2 / 2\n",
    "        return tf.where(is_small_error, squared_error, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feaeaefd-20e9-43e8-b2cb-5da0386f24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/Desktop/env/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 11 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(2.0), optimizer='nadam')\n",
    "model.save(\"my_model_with_a_custom_loss.keras\")\n",
    "### Threshold will be saved now when loaded\n",
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_loss.keras\",\n",
    "                                  custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201b086-a391-45b3-aedd-a35dc8f01a84",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "312d4304-61dc-41fd-8631-0e59eff2dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equivalent to keras.activations.softplus()\n",
    "def my_softplus(z):\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "## Equivalent to keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "## Equivalent to keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "## Equivalent to keras.constraints.nonneg()\n",
    "def my_positive_weights(weights):  # Return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weigths < 0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc756156-740f-4d11-b5a9-fd0d2f2dad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add custom components to layer\n",
    "layer = tf.keras.layers.Dense(1, activation=my_softplus,\n",
    "                             kernel_initializer=my_glorot_initializer,\n",
    "                             kernel_regularizer=my_l1_regularizer,\n",
    "                             kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e38cce-f60d-4c15-8d4e-69dd85c9dc9a",
   "metadata": {},
   "source": [
    "If the custom component has a hyperparameter that needs to be saved, use subclassing to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d95f1ac-29d2-4462-bf37-90cd58f11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c81c3-83b6-4433-b7ad-fb1d6f143846",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15434c-5caa-41a3-9a32-c812740a9ce9",
   "metadata": {},
   "source": [
    "<b>The Difference Between losses and metrics</b>\n",
    "- <b>Losses</b> like cross entropy are used by gradient descent to <b>train</b> a model, so they must be differentable and not have zero gradients everywhere. They are not supposed to be easily interpretable by humans.\n",
    "- <b>Metrics</b> are used by humans to <b>evaluate</b> a model. They must be easily interpretable, and can be non-differentable and have zero gradients everywhere<br><br>\n",
    "In most cases, a custom metrics is built the same way as a custom loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8281e321-0bce-4257-8e14-0a3748bb06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the huber loss as a metric\n",
    "model.compile(loss='mse', optimizer='nadam', metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd57a4-e4f7-4933-a417-69bdb560bd4a",
   "metadata": {},
   "source": [
    "Keras calculates the metric on each batch then outputs the mean of the metric after each epoch. However in some cases like with Precision, you don't want a mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a57dfbfe-72ca-4e1e-84bd-ad02c594e668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.800000011920929>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0,1,1,1,0,1,0,1], [1,1,0,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6242526a-e125-4986-bd1b-e6512c75366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,0,0,1,0,1,1], [1,0,1,1,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b4145-be86-47a2-bd2f-6d209ddcc9a1",
   "metadata": {},
   "source": [
    "Precision is a <b>streaming or stateful metric</b>. This means that the metric is gradually updated batch after batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90bf5baf-8a0f-4784-81ea-aae640fcf1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e268f4cc-9f24-4fae-b76f-3f121263a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>,\n",
       " <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fb19f04-c92f-404f-af88-b6653b050b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state() # Both variables get set to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5acd2da9-7b9b-497e-a42f-8f1a8f3a27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### If you want to create your own custom streaming metric, create a subclass.\n",
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    Streaming HuberMetric\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer='zeros')  ## Create variable to track sum of all Huber losses\n",
    "        self.count = self.add_weight(\"count\", initializer='zeros')  ## Create variable to track number of instances\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b213f6e-fd9d-4b54-ac5e-ee155c9f8fe6",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cd5b4-c4c7-43c2-be37-14e642bc6111",
   "metadata": {},
   "source": [
    "Occasionally you will want to build an architecture that contains an exotic layer that Tensorflow doesn't provide or you have a repetitive architecture where a particular block of layers is repeated many times and you want to just think of the blocks as one layer. For these cases, you build a custom layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfd299ba-5ebe-4f04-9034-cd9572000c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For layers without weights just use Lambda\n",
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76591d6c-3a85-4646-9908-eb60aa81a329",
   "metadata": {},
   "source": [
    "This custom layer can be used just like any other layer. <br>\n",
    "To build a custom stateful layer(i.e. a layer with weigths), you need to create a subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5973b089-e580-47e7-a286-09c51685b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def built(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='zeros')\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\":self.units,\n",
    "               'activation': tf.keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8d2d37a-082f-4ff7-a846-6145b3837683",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Layer with multiple inputs (e.g. Concatenate)\n",
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X): ## X should be a tuple of all the inputs\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b7dbb-fad3-4ea5-a7a1-6090cc079969",
   "metadata": {},
   "source": [
    "If your layer needs a different behavior during training and during testing, like Dropout or BatchNormalization, then you must add a training argument to the call() method and use it to decide what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a552df3-ea8d-4538-80a5-81ac52ffd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=False):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d5d79-efac-423f-b93c-390f6fe7cfce",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1ae72-8505-4ebf-acb5-0306611b3509",
   "metadata": {},
   "source": [
    "An intro to this topic was in Chapter 10. Use the same subclassing approach as the other custom components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2e67bc0-f9ca-42f1-8444-a8845f39e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arbitrary residual layer\n",
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation='relu', kernel_initializer='he_norm') for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1e7d272-ec4d-4a8c-ae85-1c1b3f092f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model using residual layer\n",
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation='relu', \n",
    "                                             kernel_initializer='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range (1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e37dce-6993-4dd5-a615-96cccde33ecc",
   "metadata": {},
   "source": [
    "### Losses and Metrics Based on Model Internels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938637e2-2c0d-40d0-ab36-9e013f7e1cdf",
   "metadata": {},
   "source": [
    "There may be times where you want to define losses or metrics based on other parts of your model like the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a27cd22-03db-4bff-9c84-478934096a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for a custom model with a custom reconstruction loss and a corresponding metric\n",
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                                             kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = tf.keras.metrics.Mean(\n",
    "            name='reconstruction_error'\n",
    "        )\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52605493-0be1-4632-8bda-643f6149daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1.1033 - reconstruction_error: 1.1961  \n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.4963 - reconstruction_error: 0.5125\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.4238 - reconstruction_error: 0.3807\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4006 - reconstruction_error: 0.3090  \n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.4080 - reconstruction_error: 0.3143\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   \n"
     ]
    }
   ],
   "source": [
    "# extra code\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee0506-66bb-415f-95c9-de460609f8ab",
   "metadata": {},
   "source": [
    "### Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b986d29-2af9-481c-b129-79157713c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple toy function\n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5a446ad-3e1e-47d2-b59f-2fb5f76a1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 5, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "281db3f3-d7a1-4366-897e-8983e7d95f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc38c81f-aeec-48ff-aa89-4bbd3fefecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Approximating partial derivatives\n",
    "(f(w1 + eps, w2) - f(w1,w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81df9bcd-cd44-41f9-a6a6-7a1d06b08511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1,w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76dc782b-83c6-496e-97bd-c29b8828bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "accf5042-991b-4059-8342-44bed0945b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a1cd11f-4d9b-4308-af6f-bd7e60e36220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "984499d1-897a-4aef-b307-4110bfc3a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55390873-461a-4023-b946-f4c8e51c4c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b8618-27db-444c-8329-3c4699e55efe",
   "metadata": {},
   "source": [
    "### Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e14d6-c6fb-4a21-ac0f-19643d9d96b1",
   "metadata": {},
   "source": [
    "Sometimes the fit() method may not be flexble enough for what you need to do. For example, the Wide & Deep architecture uses two different optimizers, one for the wide path, and one for the deep path. To truly implement this, you need your own custom loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f368caba-e22b-4a7a-b8d5-a9a4e106de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build simple model\n",
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81adc80d-5057-47d6-a2c4-fd0503ebb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create function that will randomly sample a batch of instances from training set\n",
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea8bcd51-c2a7-4216-982a-e8282e6fd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\" for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3feea7d6-d946-4716-9ef6-b0a65121cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "mean_loss = tf.keras.metrics.Mean(name='mean_loss')\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "503e1fc1-f6b1-4983-aab9-3af20e06ac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 - mean_loss: 2.8851 - mean_absolute_error: 0.6608\n",
      "Epoch 2/5\n",
      "362/362 - mean_loss: 1.6547 - mean_absolute_error: 0.5443\n",
      "Epoch 3/5\n",
      "362/362 - mean_loss: 1.0461 - mean_absolute_error: 0.4979\n",
      "Epoch 4/5\n",
      "362/362 - mean_loss: 0.7997 - mean_absolute_error: 0.4943\n",
      "Epoch 5/5\n",
      "362/362 - mean_loss: 0.7059 - mean_absolute_error: 0.4992\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81f298-86ea-48c6-987f-27e241ea8fcb",
   "metadata": {},
   "source": [
    "## Tensorflow Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a5f718d-600f-428e-9f01-4563b931ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27ef9469-f2ca-4a77-9155-921b2ab2064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Python function\n",
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4ef2195-1d15-46e8-b7ff-b49f4502577d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x742fafd98740>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to Tensorflow Function\n",
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "393d9d5a-a878-462a-a5d1-cc34c6e73307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e12f54ca-8f63-4a81-aacd-14a2e9535a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f94e2607-a4e1-43a0-97c0-e8b67a29ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db287850-ef67-4424-9587-df971ed17cf7",
   "metadata": {},
   "source": [
    "A TF Function optimizes the computation graph, pruning unused nodes, simplifying expressions, running operation in parallel and more.<br>\n",
    "Because of this TF Functions run faster than Python functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05244c2-1cbb-4aa8-83ae-e3b5e84d930f",
   "metadata": {},
   "source": [
    "When creating a custom metric, layer, loss function, etc and use it in Keras, if automaticlly converts it into a TF Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16fb1d-5764-480b-b2d2-f4aba874d04e",
   "metadata": {},
   "source": [
    "### AutoGraph and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5853f89-12f2-43ff-8b30-c33b9f5efa87",
   "metadata": {},
   "source": [
    "TF generates graphs by first analyzing the Python function's source code to capture all the control flow statements, such as for loops, while loops, if statements, etc. This first step is called <b>AutoGraph</b>. After analyzing the function's code, AutoGraph outputs an upgraded version of that function in which all the control flow statements are replaced by the appropriate TensorFlow operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af7f2d-86b8-49cf-8c46-001430539bad",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5927b-4aec-4ab2-842c-f220e025f76b",
   "metadata": {},
   "source": [
    "## 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bacb02-d6fe-4f25-8cdf-ef39dd33fd05",
   "metadata": {},
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58eb73-f678-4fe8-8765-4b7526391b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
